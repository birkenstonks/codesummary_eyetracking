{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This script splits bounding boxes that have a function call \n",
    "using the dot operator.\n",
    "- For mapping bounding boxes to parts of the code, it's easier\n",
    "to separate these than it is to leave them in. \n",
    "- That's because scrML splits these as it makes the ASTs \n",
    "- (e.g. clock.getCurrentTime --> 'clock', '.', 'getCurrentTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_files = os.listdir(\"./word_coordinates_final/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks whether the word is \"null\", and makes sure \"null\" is still put\n",
    "# into final file\n",
    "def check_word(word):\n",
    "    if isinstance(word, float) and math.isnan(word):\n",
    "        return \"null\"\n",
    "    return word\n",
    "\n",
    "# for each bounding box, calculates the char width to ensure reliable splits\n",
    "def calculate_char_width(row):\n",
    "    return row['width'] / len(row['word'])\n",
    "\n",
    "# for words with a dot (e.g. System.out.println), splits and puts each part into a new row\n",
    "def split_word(row, char_width):\n",
    "    parts = re.split(\"\\.\", row['word'])\n",
    "    new_x = row['x']\n",
    "    replacement = pd.DataFrame()\n",
    "\n",
    "    for j, string in enumerate(parts):\n",
    "        word_width = round(len(string)*char_width)\n",
    "        if word_width == 0:\n",
    "            continue\n",
    "        new_row = pd.Series([string, 0, new_x, row['y'], word_width, row['height'], new_x / 1920,\n",
    "                             row['tobii_y'], word_width / 1920, row['tobii_height']])\n",
    "        replacement = pd.concat([replacement, new_row], ignore_index=True, axis=1)\n",
    "        new_x += (word_width + char_width) # moving x coordinate by word size\n",
    "\n",
    "    return replacement\n",
    "\n",
    "# occurrences got messed up splitting the boxes, so this recalculates for each word\n",
    "def recalculate_num_occurrences(new_boxes): \n",
    "    occurrences = {}\n",
    "    for i, row in new_boxes.iterrows():\n",
    "        word = row['word']\n",
    "        if word not in occurrences:\n",
    "            occurrences[word] = 0\n",
    "        else:\n",
    "            occurrences[word] += 1\n",
    "        row['occurrence'] = occurrences[word]\n",
    "    return new_boxes\n",
    "\n",
    "def process_file(file, new_boxes):\n",
    "    name = re.sub(\"_boxes.csv\", \"\", file)\n",
    "    boxes = pd.read_csv(f'./word_coordinates_final/{file}')\n",
    "\n",
    "    for i, row in boxes.iterrows():\n",
    "        row['word'] = check_word(row['word'])\n",
    "\n",
    "        if isinstance(row['word'], str) and re.search(\"\\.\", row['word']):\n",
    "            char_width = calculate_char_width(row)\n",
    "            replacement = split_word(row, char_width)\n",
    "\n",
    "            replacement.index = new_boxes.index\n",
    "            new_boxes = pd.concat([new_boxes, replacement], ignore_index=True, axis=1)\n",
    "        else:\n",
    "            new_boxes = pd.concat([new_boxes, row.T], ignore_index=True, axis=1)\n",
    "            \n",
    "    new_boxes = recalculate_num_occurrences(new_boxes.T)\n",
    "    new_boxes.to_csv(f\"word_coordinates_split/{file}\", index=False, header=[\n",
    "        'word', 'occurrence', 'x', 'y', 'width', 'height', 'tobii_x',\n",
    "        'tobii_y', 'tobii_width', 'tobii_height'])\n",
    "\n",
    "\n",
    "\n",
    "for file in box_files:\n",
    "    new_boxes = pd.DataFrame()\n",
    "    process_file(file, new_boxes)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "null\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "### SAME CODE AS ABOVE, BUT LESS MODULARIZED\n",
    "\n",
    "\n",
    "# # goes through all the words in all the files to find cases where there's a dot (e.g. \"System.out.println\")\n",
    "# for file in box_files:\n",
    "#     name = re.sub(\"_boxes.csv\", \"\", file)\n",
    "#     boxes = pd.read_csv(f'./word_coordinates_final/{file}') # getting corresponding bounding box file\n",
    "#     new_boxes = pd.DataFrame() # used for accumulating new rows\n",
    "    \n",
    "#     for i, row in boxes.iterrows():\n",
    "#         word = row['word']\n",
    "        \n",
    "#         if isinstance(word, float) and math.isnan(word): # checking if the word is \"null\" and makes sure \"null\"\n",
    "#             row['word'] = \"null\"                         # is still in final file\n",
    "            \n",
    "            \n",
    "#         if isinstance(word, str) and re.search(\"\\.\", word): # if there's a dot in the word, split\n",
    "#             char_width = row['width']/len(word) # used for gauging the pixel width of the word parts\n",
    "#             parts = re.split(\"\\.\", word)\n",
    "#             new_x = row['x']\n",
    "#             replacement = pd.DataFrame() # used for collecting the newly split up word\n",
    "            \n",
    "#             for j, string in enumerate(parts): # perform this function for all parts of the original word\n",
    "#                 word_width = round(len(string)*char_width)\n",
    "#                 if word_width == 0: continue # sometimes the dot is at the end of a word (e.g. \"fail.\")\n",
    "                \n",
    "#                 # making new row to concatenate with original dataframe. Scaling tobii width to screen width (1920px) \n",
    "#                 new_row = pd.Series([string, 0, new_x, row['y'], word_width, row['height'], new_x / 1920, \n",
    "#                                      row['tobii_y'], word_width / 1920, row['tobii_height']])\n",
    "#                 replacement = pd.concat([replacement, new_row], ignore_index=True, axis=1)\n",
    "#                 new_x += (word_width + char_width) # adding char_width to account for the \".\" (e.g. System.out.println)\n",
    "            \n",
    "#             replacement.index = new_boxes.index\n",
    "#             new_boxes = pd.concat([new_boxes, replacement], ignore_index=True, axis=1)\n",
    "            \n",
    "#         else: # if there wasn't a period, just add the row to the dataframe\n",
    "#             new_boxes = pd.concat([new_boxes, row.T], ignore_index=True, axis=1)\n",
    "            \n",
    "#     new_boxes.T.to_csv(\"/word_coordinates_split/{file}\", index=False, header=[\n",
    "#         'word', 'occurrence', 'x', 'y', 'width', 'height', 'tobii_x',\n",
    "#         'tobii_y', 'tobii_width', 'tobii_height'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
