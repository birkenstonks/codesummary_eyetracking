{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure Fixation Count and Fixation Duration Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import my_stats\n",
    "import scipy.stats as stats\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_averages(filename, filepath):\n",
    "    df = pd.read_csv(f\"{filepath}/{filename}\")\n",
    "    counts = df.iloc[:, 1:]\n",
    "    num_tokens = df.shape[1]\n",
    "    num_participants = df.shape[0]\n",
    "    # print(\"total shape: \", df.shape, \"num tokens: \", num_tokens, \"participants: \", num_participants)\n",
    "    row_sums = counts.sum(axis=1)\n",
    "    # print('row sums', row_sums)\n",
    "    # p_averages = row_sums/num_tokens\n",
    "    # print(f\"participant averages? {len(participant_averages)}\\n\", participant_averages)\n",
    "    participant_sums = dict(zip(df.iloc[:, 0], row_sums))\n",
    "    total_sum = sum(row_sums)\n",
    "    fc_avg = total_sum/num_participants\n",
    "    # print(\"sums\", fc_avg, row_sums, row_count)\n",
    "    \n",
    "    return fc_avg, participant_sums\n",
    "    # return total sum, and dictionary of participants \n",
    "    \n",
    "\n",
    "def calculate_duration_averages(filename, filepath):\n",
    "    df = pd.read_csv(f\"{filepath}/{filename}\")\n",
    "    counts = df.iloc[:, 1:]\n",
    "    row_sums = counts.sum(axis=1)\n",
    "    row_nonzeros = counts.apply(lambda x: np.count_nonzero(x), axis=1)\n",
    "    row_averages = row_sums.div(row_nonzeros).replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "    count_nonzeros = len(np.where(counts != 0)[0])\n",
    "    participant_averages = dict(zip(df.iloc[:, 0], row_averages))\n",
    "    total_average = sum(row_sums)/count_nonzeros\n",
    "    \n",
    "    return total_average, participant_averages\n",
    "\n",
    "\n",
    "def cohens_d(list1, list2):\n",
    "    n1, n2 = len(list1), len(list2)\n",
    "    s1, s2 = np.nanvar(list1, ddof=1), np.nanvar(list2, ddof=1)\n",
    "    pooled_var = ((n1-1) * s1 + (n2-1) * s2) / (n1 + n2 - 2)\n",
    "    return (np.nanmean(list1) - np.nanmean(list2)) / np.sqrt(pooled_var)\n",
    "\n",
    "\n",
    "def decide_t_test(g1_data, g2_data):  # based on variance, decide which t-test to use\n",
    "    g1var = np.nanvar(g1_data, ddof=1)\n",
    "    g2var = np.nanvar(g2_data, ddof=1)\n",
    "    larger = max(g1var, g2var)\n",
    "    smaller = min(g1var, g2var)\n",
    "    # ratio = larger/smaller\n",
    "    # test = \"Student's\" # only using Welch's so t-values can be compared\n",
    "    # equal_var = True\n",
    "    # if ratio >= 4:\n",
    "    #     test = \"Welch's\"\n",
    "    equal_var = False\n",
    "    return \"Welch's\", equal_var\n",
    "\n",
    "\n",
    "def my_t_test(name1, name2, g1_data, g2_data):\n",
    "    output = {'test used': [],\n",
    "              f\"{name1} avg\": [],\n",
    "              f\"{name2} avg\": [],\n",
    "              't-value': [],\n",
    "              'p-value': [],\n",
    "              'effect size': []\n",
    "              }\n",
    "\n",
    "    # g1_data = np.array(g1_data)[~np.isnan(g1_data)]\n",
    "    # g2_data = np.array(g2_data)[~np.isnan(g2_data)]\n",
    "    print(\"means\", mean(g1_data), mean(g2_data), len(g1_data), len(g2_data))\n",
    "    if len(g1_data) >= 2 and len(g2_data) >= 2:\n",
    "        test, equal_var = decide_t_test(g1_data, g2_data)\n",
    "        t, p = stats.ttest_ind(a=g1_data, b=g2_data, equal_var=equal_var)\n",
    "        d = cohens_d(g1_data, g2_data)\n",
    "\n",
    "        output['test used'].append(test)\n",
    "        output[f\"{name1} avg\"].append(mean(g1_data))\n",
    "        output[f\"{name2} avg\"].append(mean(g2_data))\n",
    "        output['t-value'].append(t)\n",
    "        output['p-value'].append(p)\n",
    "        output['effect size'].append(d)\n",
    "\n",
    "    else:\n",
    "        print(f\"not enough data points to calculate variance\")\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = ['189', '310', '311', '312', '313', '315', '316', '318', '319']\n",
    "novices = ['111', '117', '129', '139', '147', '168', '176', '182', '186', '191']\n",
    "women = ['111', '117', '119', '129', '136', '166', '182', '317', '319']\n",
    "total_gaze_measures = {\n",
    "    # total fixation counts and durations split by task\n",
    "    'fcr':[], 'fcw':[], 'fdr':[], 'fdw':[],\n",
    "    \n",
    "    # fixation counts and durations split by expertise\n",
    "    'fcexpr':[], 'fcexpw':[], 'fcnovr':[], 'fcnovw':[],\n",
    "    'fdexpr':[], 'fdexpw':[], 'fdnovr':[], 'fdnovw':[],\n",
    "    \n",
    "    # fixation counts and durations split by gender\n",
    "    'fcwomr':[], 'fcwomw':[], 'fcmenr':[], 'fcmenw':[], \n",
    "    'fdwomr':[], 'fdwomw':[], 'fdmenr':[], 'fdmenw':[] \n",
    "}\n",
    "\n",
    "fixpath = \"abstract_fixation_counts\"\n",
    "durpath = \"abstract_fixation_durations\"\n",
    "fc_dir = os.listdir(fixpath)\n",
    "fd_dir = os.listdir(durpath)\n",
    "\n",
    "for task in fc_dir:\n",
    "    # task = reading or writing\n",
    "    subfixpath = f\"{fixpath}/{task}\"\n",
    "    subdurpath = f\"{durpath}/{task}\"\n",
    "    fixfiles = os.listdir(subfixpath)\n",
    "    durfiles = os.listdir(subdurpath)\n",
    "    \n",
    "    if task == 'reading':\n",
    "        task_str = 'r'\n",
    "    elif task == 'writing':\n",
    "        task_str = 'w'\n",
    "    fixkey = 'fc'+task_str\n",
    "    durkey = 'fd'+task_str\n",
    "        \n",
    "    for file in fixfiles:\n",
    "        # print(file)\n",
    "        # print(task)\n",
    "        file_fc_avg, participant_fc_avg = calculate_averages(file, subfixpath) # averages\n",
    "        file_fd_avg, participant_fd_avg = calculate_duration_averages(file, subdurpath) # averages\n",
    "        \n",
    "        total_gaze_measures[fixkey].append(file_fc_avg)\n",
    "        total_gaze_measures[durkey].append(file_fd_avg)\n",
    "        \n",
    "        keys = []\n",
    "        for person, number in participant_fc_avg.items():\n",
    "            new_person = str(person)\n",
    "            if new_person in women:\n",
    "                # print(\"woman\", new_person)\n",
    "                gen_fc_key = 'fcwom'+task_str\n",
    "                gen_fd_key = 'fdwom'+task_str\n",
    "            else:\n",
    "                # print(\"man\", new_person)\n",
    "                gen_fc_key = 'fcmen'+task_str\n",
    "                gen_fd_key = 'fdmen'+task_str\n",
    "            total_gaze_measures[gen_fc_key].append(participant_fc_avg[person])\n",
    "            total_gaze_measures[gen_fd_key].append(participant_fd_avg[person])\n",
    "                \n",
    "            if new_person in experts:\n",
    "                # print(\"expert\", new_person)\n",
    "                exp_fc_key = 'fcexp'+task_str\n",
    "                exp_fd_key = 'fdexp'+task_str\n",
    "            elif new_person in novices:\n",
    "                # print(\"novice\", new_person)\n",
    "                exp_fc_key = 'fcnov'+task_str\n",
    "                exp_fd_key = 'fdnov'+task_str\n",
    "            else:\n",
    "                continue\n",
    "            total_gaze_measures[exp_fc_key].append(participant_fc_avg[person])\n",
    "            total_gaze_measures[exp_fd_key].append(participant_fd_avg[person])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers(data):\n",
    "#     q1, q3 = np.percentile(data, [25, 75])\n",
    "#     iqr = q3 - q1\n",
    "#     lower_bound = q1 - (1.5 * iqr)\n",
    "#     upper_bound = q3 + (1.5 * iqr)\n",
    "\n",
    "#     return [x for x in data if lower_bound <= x <= upper_bound]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_gaze_measures = {k : remove_outliers(v) for k, v in total_gaze_measures.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing\n",
      "Experts:81.69302325581396, Novices: 106.60743801652893\n",
      "Experts:0.08712404977964776, Novices: 0.11991097154834611\n",
      "\n",
      "Reading\n",
      "Experts:23.5625, Novices: 55.58967391304348\n",
      "Experts:0.06269816058109995, Novices: 0.11331992054067863\n"
     ]
    }
   ],
   "source": [
    "# # fixation counts and durations split by expertise\n",
    "# 'fcexpr': [], 'fcexpw': [], 'fcnovr': [], 'fcnovw': [],\n",
    "# 'fdexpr': [], 'fdexpw': [], 'fdnovr': [], 'fdnovw': [],\n",
    "# print(\"Writing\")\n",
    "# print(f\"Experts:{mean(total_gaze_measures['fcexpw'])}, Novices: {mean(total_gaze_measures['fcnovw'])}\")\n",
    "# print(f\"Experts:{mean(total_gaze_measures['fdexpw'])}, Novices: {mean(total_gaze_measures['fdnovw'])}\\n\")\n",
    "\n",
    "# print(\"Reading\")\n",
    "# print(f\"Experts:{mean(total_gaze_measures['fcexpr'])}, Novices: {mean(total_gaze_measures['fcnovr'])}\")\n",
    "# print(f\"Experts:{mean(total_gaze_measures['fdexpr'])}, Novices: {mean(total_gaze_measures['fdnovr'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average fixation count for Reading:  38.98649324485426\n",
      "average fixation duration for Reading:  0.1030644080906216\n",
      "average fixation count for Writing:  94.92109895656294\n",
      "average fixation duration for Writing:  0.11432642743150927\n"
     ]
    }
   ],
   "source": [
    "print(\"average fixation count for Reading: \", mean(total_gaze_measures['fcr']))\n",
    "print(\"average fixation duration for Reading: \", mean(total_gaze_measures['fdr']))\n",
    "\n",
    "print(\"average fixation count for Writing: \", mean(total_gaze_measures['fcw']))\n",
    "print(\"average fixation duration for Writing: \", mean(total_gaze_measures['fdw']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test used': [\"Welch's\"],\n",
       " 'reading fc avg': [38.98649324485426],\n",
       " 'writing fc avg': [94.92109895656294],\n",
       " 't-value': [-9.585027422730311],\n",
       " 'p-value': [2.4072376021628875e-15],\n",
       " 'effect size': [-1.6956700178498216]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO t-tests\n",
    "my_stats.my_t_test(\"reading fc\", \"writing fc\", total_gaze_measures['fcr'], total_gaze_measures['fcw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test used': [\"Welch's\"],\n",
       " 'reading fd avg': [0.1030644080906216],\n",
       " 'writing fd avg': [0.11432642743150927],\n",
       " 't-value': [-1.8500732219633098],\n",
       " 'p-value': [0.06632950226879404],\n",
       " 'effect size': [-0.29723804300057555]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stats.my_t_test(\"reading fd\", \"writing fd\",total_gaze_measures['fdr'], total_gaze_measures['fdw'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means 23.5625 55.58967391304348 336 368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test used': [\"Welch's\"],\n",
       " 'exp reading fc avg': [23.5625],\n",
       " 'nov reading fc avg': [55.58967391304348],\n",
       " 't-value': [-10.343369916513725],\n",
       " 'p-value': [2.8112494921281863e-23],\n",
       " 'effect size': [-0.7660194765594568]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(\"exp reading fc\", \"nov reading fc\", total_gaze_measures['fcexpr'], total_gaze_measures['fcnovr'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means 0.06269816058109995 0.11331992054067863 336 368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test used': [\"Welch's\"],\n",
       " 'exp reading fd avg': [0.06269816058109995],\n",
       " 'nov reading fd avg': [0.11331992054067863],\n",
       " 't-value': [-8.197665047763548],\n",
       " 'p-value': [1.4572617482044437e-15],\n",
       " 'effect size': [-0.6053449257544024]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(\"exp reading fd\", \"nov reading fd\", total_gaze_measures['fdexpr'], total_gaze_measures['fdnovr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means 81.69302325581396 106.60743801652893 215 242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test used': [\"Welch's\"],\n",
       " 'exp writing fc avg': [81.69302325581396],\n",
       " 'nov writing fc avg': [106.60743801652893],\n",
       " 't-value': [-2.9396402171755205],\n",
       " 'p-value': [0.003461620227716573],\n",
       " 'effect size': [-0.2772198488149874]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(\"exp writing fc\", \"nov writing fc\",\n",
    "          total_gaze_measures['fcexpw'], total_gaze_measures['fcnovw'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means 0.08712404977964776 0.11991097154834611 215 242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test used': [\"Welch's\"],\n",
       " 'exp writing fd avg': [0.08712404977964776],\n",
       " 'nov writing fd avg': [0.11991097154834611],\n",
       " 't-value': [-6.013665692540119],\n",
       " 'p-value': [3.740048898072501e-09],\n",
       " 'effect size': [-0.5619470571248397]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_t_test(\"exp writing fd\", \"nov writing fd\",\n",
    "          total_gaze_measures['fdexpw'], total_gaze_measures['fdnovw'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time in hours:  35.67536585277777\n",
      "java tasks:  1684\n",
      "eye-tracking data points:  6848501\n"
     ]
    }
   ],
   "source": [
    "participantfiles = \"/home/zachkaras/code_summ_data\"\n",
    "people = os.listdir(participantfiles)\n",
    "\n",
    "time = 0 # time in seconds\n",
    "datapoints = 0\n",
    "tasks = 0\n",
    "for person in people:\n",
    "    gazefiles = os.listdir(f\"{participantfiles}/{person}/annotated_gaze\")\n",
    "    tasks += len(gazefiles)\n",
    "    for file in gazefiles:\n",
    "        df = pd.read_csv(f\"{participantfiles}/{person}/annotated_gaze/{file}\")\n",
    "        start = df.loc[0, 'system_timestamp']\n",
    "        end = df.loc[len(df)-1, 'system_timestamp']\n",
    "        diff = (end-start)/10**6\n",
    "        time += diff\n",
    "        datapoints += len(df)\n",
    "print(\"time in hours: \", time/3600)\n",
    "print(\"java tasks: \", tasks)\n",
    "print(\"eye-tracking data points: \", datapoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.67536585277777"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time/3600 # time in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
